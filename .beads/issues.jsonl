{"id":"gains-0a9","title":"Replace dynamic State with generic struct-based state","description":"## IMPLEMENTATION IN PROGRESS\n\n### Completed:\n- Step[S] generic interface with Dependencies()\n- FuncStep[S] with Reads()/Writes() builders\n- PromptStep[S,T] with setter pattern (plain text + structured)\n- ToolStep[S,T] with ToolStepOutput preserving args\n- Chain[S] with Validate() and ValidateWithInputs()\n- Loop[S] with ExitCondition[S], NewLoopUntil, NewLoopWhile, NewLoopN\n\n### In Progress:\n- Parallel[S] with DeepClone\n- Router[S]\n\n### Pending:\n- Remove old typed.go (Key[T] system)\n- Remove old state.go helpers\n- Update Workflow wrapper\n- Update/remove agent_step.go\n- Update tests\n- Update merge.go aggregators\n\n---\n\nReplace the dynamic `map[string]any` State with user-defined struct types, making all steps generic over the state type. This provides compile-time type safety, IDE support, and enables construction-time dependency validation.\n\n[Rest of original description...]","status":"in_progress","priority":1,"issue_type":"feature","created_at":"2025-12-19T09:22:31.241069708-08:00","updated_at":"2025-12-19T09:51:26.695957457-08:00"}
{"id":"gains-1ij","title":"ToolStep[T] should preserve typed args in output","description":"Preserve the typed arguments `T` in ToolStep output so downstream steps can access the original structured args, not just the string result.\n\n## Problem\n\n`ToolStep[T]` accepts a typed args function but discards the type information:\n\n```go\n// workflow/tool_step.go - current flow\n\n// 1. Build typed args (T is preserved here)\nargs, err := t.argsFunc(state)  // returns T\n\n// 2. Marshal to JSON (T is lost here)\nargsJSON, err := json.Marshal(args)\n\n// 3. Execute tool\ncall := ai.ToolCall{Arguments: string(argsJSON)}\nresult, err := t.registry.Execute(ctx, call)\n\n// 4. Store only string result (T is gone)\nstate.Set(t.outputKey, result.Content)  // string only\n```\n\n**What's lost:**\n- The structured args `T` that was carefully built from state\n- Type safety for downstream steps\n- Ability to inspect/log/retry with the original args\n\n**Example scenario:**\n```go\ntype SearchArgs struct {\n    Query string `json:\"query\"`\n    Limit int    `json:\"limit\"`\n}\n\nstep := NewToolStep(\"search\", registry, \"web_search\",\n    func(s *State) (SearchArgs, error) {\n        return SearchArgs{Query: s.GetString(\"topic\"), Limit: 10}, nil\n    },\n    \"search_output\",\n)\n\n// After execution:\n// - state[\"search_output\"] = \"Results: ...\" (string)\n// - Original SearchArgs{Query: \"AI safety\", Limit: 10} is LOST\n//\n// Downstream step wants to say \"Based on your search for 'AI safety'...\"\n// but can't access the original query without re-reading \"topic\" from state\n```\n\n## Solution\n\nIntroduce `ToolStepOutput[T]` to bundle args and result:\n\n```go\n// ToolStepOutput holds both the typed arguments and string result\n// from a tool execution.\ntype ToolStepOutput[T any] struct {\n    Args   T      // Original typed arguments\n    Result string // Tool execution result\n}\n```\n\nUpdate storage in `Run()`:\n\n```go\n// Current (line 117-118):\nif t.outputKey != \"\" {\n    state.Set(t.outputKey, result.Content)\n}\n\n// Proposed:\nif t.outputKey != \"\" {\n    state.Set(t.outputKey, \u0026ToolStepOutput[T]{\n        Args:   args,\n        Result: result.Content,\n    })\n}\n```\n\nUpdate `StepResult.Output` similarly:\n\n```go\n// Current (line 121-128):\nreturn \u0026StepResult{\n    StepName: t.name,\n    Output:   result.Content,  // string\n    ...\n}\n\n// Proposed:\nreturn \u0026StepResult{\n    StepName: t.name,\n    Output:   \u0026ToolStepOutput[T]{Args: args, Result: result.Content},\n    ...\n}\n```\n\n## Usage After Change\n\n```go\n// Reading tool output with full type safety\noutput := workflow.MustGet[*ToolStepOutput[SearchArgs]](searchOutputKey, state)\nfmt.Printf(\"Searched for: %s\\n\", output.Args.Query)\nfmt.Printf(\"Results: %s\\n\", output.Result)\n\n// Or via StepResult\nresult, _ := step.Run(ctx, state)\noutput := result.Output.(*ToolStepOutput[SearchArgs])\n```\n\n## Alternative Considered: Two Type Parameters\n\n```go\ntype ToolStep[TArgs, TResult any] struct { ... }\n```\n\nThis would allow typed results too, parsing JSON tool output into `TResult`. However:\n- Many tools return plain text, not JSON\n- Adds complexity for marginal benefit\n- Users can parse `Result` string downstream if needed\n\n**Decision:** Keep single type parameter for args. Result stays string. This solves the primary problem (lost args) without over-engineering.\n\n## Alternative Considered: Separate Keys\n\nStore args under `outputKey + \"_args\"` and result under `outputKey`:\n\n```go\nstate.Set(t.outputKey, result.Content)\nstate.Set(t.outputKey+\"_args\", args)\n```\n\n**Rejected because:**\n- Pollutes state namespace\n- Two keys to track instead of one\n- Harder to clean up\n- Less discoverable\n\n## Changes Required\n\n### workflow/tool_step.go\n\n1. Add `ToolStepOutput[T]` type definition\n2. Update `Run()` to store `*ToolStepOutput[T]` instead of string (line 117-118)\n3. Update `Run()` return to use `*ToolStepOutput[T]` in Output (line 123)\n4. Update godoc examples\n\n### workflow/typed.go (optional)\n\nAdd helper for reading tool output:\n\n```go\n// GetToolOutput retrieves a ToolStepOutput from state.\nfunc GetToolOutput[T any](key Key[*ToolStepOutput[T]], state *State) (*ToolStepOutput[T], bool) {\n    return Get(key, state)\n}\n```\n\n### Tests\n\nUpdate tests to expect `*ToolStepOutput[T]` instead of string.\n\n### Migration Impact\n\n**Breaking change** - code reading tool output as string will break:\n\n```go\n// Before:\nresult := state.GetString(\"search_output\")\n\n// After:\noutput := workflow.MustGet[*ToolStepOutput[SearchArgs]](key, state)\nresult := output.Result\n```\n\nConsider documenting migration path clearly.\n\n## Files\n\n- `workflow/tool_step.go`\n- `workflow/typed.go` (optional helper)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T08:39:26.822671736-08:00","updated_at":"2025-12-19T08:39:40.249614628-08:00","dependencies":[{"issue_id":"gains-1ij","depends_on_id":"gains-0a9","type":"blocks","created_at":"2025-12-19T09:23:28.423537306-08:00","created_by":"daemon"}]}
{"id":"gains-21z","title":"Clarify Loop condition semantics with ExitCondition rename","description":"Rename `LoopCondition` to `ExitCondition` and `NewLoop` to `NewLoopWithExitCondition` to clarify semantics, while keeping simple helpers as the primary API.\n\n## Problem\n\nCurrent `LoopCondition` semantics are counterintuitive:\n\n```go\n// Current: return true to EXIT (backwards from natural reading)\ntype LoopCondition func(ctx context.Context, state *State) bool\n\nNewLoop(\"retry\", step, func(ctx context.Context, state *State) bool {\n    return state.GetInt(\"attempts\") \u003e= 3  // \"return true to stop\" - confusing\n})\n```\n\nUsers naturally expect `true` to mean \"yes, keep looping\" but it means the opposite.\n\nAdditionally, accessing the iteration count requires reading from state:\n```go\niter := state.GetInt(\"retry_iteration\")  // awkward\n```\n\n## Solution\n\n### 1. Rename LoopCondition to ExitCondition\n\n```go\n// ExitCondition determines when the loop should stop.\n// Return true to EXIT the loop, false to continue iterating.\n// The iteration parameter is 1-indexed (first iteration is 1).\ntype ExitCondition func(ctx context.Context, state *State, iteration int) bool\n```\n\nThe name `ExitCondition` makes the semantics explicit - you're defining *when to exit*.\n\n### 2. Add iteration parameter\n\nNo more reading from state:\n```go\n// Before\nfunc(ctx context.Context, state *State) bool {\n    iter := state.GetInt(\"myloop_iteration\")\n    return iter \u003e= 3\n}\n\n// After\nfunc(ctx context.Context, state *State, iteration int) bool {\n    return iteration \u003e= 3\n}\n```\n\n### 3. Rename NewLoop to NewLoopWithExitCondition\n\n```go\n// Before (confusing name, unclear what condition does)\nNewLoop(\"retry\", step, condition, opts...)\n\n// After (self-documenting)\nNewLoopWithExitCondition(\"retry\", step, exitCondition, opts...)\n```\n\n### 4. Keep simple helpers as primary API\n\nMost users should never need to write conditions:\n\n```go\n// Recommended for most cases - no condition function needed\nNewLoopUntil[T](name, step, key, value, opts...)     // exit when key == value\nNewLoopWhile[T](name, step, key, value, opts...)     // exit when key != value\nNewLoopUntilSet[T](name, step, key, opts...)         // exit when key is truthy\n\n// Escape hatch for complex cases\nNewLoopWithExitCondition(name, step, exitCond, opts...)\n```\n\n## Final API\n\n```go\n// ExitCondition determines when the loop should stop.\n// Return true to EXIT the loop, false to continue iterating.\n// The iteration parameter is 1-indexed (first iteration is 1).\ntype ExitCondition func(ctx context.Context, state *State, iteration int) bool\n\n// --- Primary API (simple helpers) ---\n\n// NewLoopUntil creates a loop that exits when key equals value.\n// This is the recommended way to create loops for most use cases.\nfunc NewLoopUntil[T comparable](name string, step Step, key Key[T], value T, opts ...LoopOption) *Loop\n\n// NewLoopWhile creates a loop that continues while key equals value.\n// Exits when the key no longer equals value (or is not set).\nfunc NewLoopWhile[T comparable](name string, step Step, key Key[T], value T, opts ...LoopOption) *Loop\n\n// NewLoopUntilSet creates a loop that exits when key has a truthy value.\nfunc NewLoopUntilSet[T any](name string, step Step, key Key[T], opts ...LoopOption) *Loop\n\n// --- Escape Hatch (custom conditions) ---\n\n// NewLoopWithExitCondition creates a loop with a custom exit condition.\n// Use this for complex conditions that can't be expressed with the simple helpers.\n//\n// Example:\n//\n//     loop := NewLoopWithExitCondition(\"refine\", step,\n//         func(ctx context.Context, state *State, iteration int) bool {\n//             // Exit after 5 iterations OR when quality threshold is met\n//             return iteration \u003e= 5 || state.GetFloat(\"quality\") \u003e 0.95\n//         },\n//     )\nfunc NewLoopWithExitCondition(name string, step Step, cond ExitCondition, opts ...LoopOption) *Loop\n```\n\n## Usage Examples\n\n```go\n// Simple: exit when \"done\" key is true\ndoneKey := workflow.BoolKey(\"done\")\nloop := workflow.NewLoopUntil(\"process\", step, doneKey, true)\n\n// Simple: exit when \"status\" equals \"complete\"\nstatusKey := workflow.StringKey(\"status\")\nloop := workflow.NewLoopUntil(\"process\", step, statusKey, \"complete\")\n\n// Simple: exit when \"result\" has any truthy value\nresultKey := workflow.StringKey(\"result\")\nloop := workflow.NewLoopUntilSet(\"process\", step, resultKey)\n\n// Complex: custom multi-condition exit\nloop := workflow.NewLoopWithExitCondition(\"refine\", step,\n    func(ctx context.Context, state *State, iteration int) bool {\n        // Exit conditions:\n        // 1. Max 10 iterations\n        // 2. Quality score above threshold\n        // 3. User requested stop\n        if iteration \u003e= 10 {\n            return true\n        }\n        if state.GetFloat(\"quality\") \u003e 0.95 {\n            return true\n        }\n        return state.GetBool(\"stop_requested\")\n    },\n)\n```\n\n## Changes Required\n\n### workflow/loop.go\n\n1. Rename `LoopCondition` → `ExitCondition`\n2. Change signature: add `iteration int` parameter\n3. Rename `NewLoop` → `NewLoopWithExitCondition`\n4. Update internal condition field and calls\n5. Update simple helpers to use new internal API\n6. Update godoc comments\n\n### Internal Changes\n\n```go\n// Before\ntype Loop struct {\n    condition LoopCondition\n}\n\n// After\ntype Loop struct {\n    exitCondition ExitCondition\n}\n```\n\n```go\n// Run method - before\nif l.condition(ctx, state) {\n    return ...\n}\n\n// Run method - after  \nif l.exitCondition(ctx, state, i) {\n    return ...\n}\n```\n\n### Simple helpers implementation\n\n```go\nfunc NewLoopUntil[T comparable](name string, step Step, key Key[T], value T, opts ...LoopOption) *Loop {\n    return NewLoopWithExitCondition(name, step, func(ctx context.Context, state *State, _ int) bool {\n        v, ok := Get(state, key)\n        return ok \u0026\u0026 v == value\n    }, opts...)\n}\n```\n\n### Tests\n\n- Update all tests using `NewLoop` to `NewLoopWithExitCondition`\n- Update condition signatures to include iteration parameter\n- Add tests verifying iteration parameter is correct (1-indexed)\n\n## Migration\n\n| Before | After |\n|--------|-------|\n| `LoopCondition` | `ExitCondition` |\n| `NewLoop(name, step, cond)` | `NewLoopWithExitCondition(name, step, cond)` |\n| `func(ctx, state) bool` | `func(ctx, state, iteration) bool` |\n\n**Breaking change**: Condition signature changes. Users with custom conditions must add the iteration parameter.\n\n## Alternative Considered: Invert to ContinueCondition\n\n```go\ntype ContinueCondition func(...) bool  // true = CONTINUE\n```\n\n**Rejected because:**\n- Still requires writing conditions for simple cases\n- \"When should I continue?\" is equally confusing as \"when should I exit?\"\n- The simple helpers (`NewLoopUntil`, etc.) are better for most cases\n- `ExitCondition` with explicit naming is clearer than implicit inversion\n\n## Files\n\n- `workflow/loop.go`","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T08:46:46.710583366-08:00","updated_at":"2025-12-19T08:47:15.764179584-08:00","dependencies":[{"issue_id":"gains-21z","depends_on_id":"gains-0a9","type":"blocks","created_at":"2025-12-19T09:23:28.501586016-08:00","created_by":"daemon"}]}
{"id":"gains-25z","title":"Document state snapshot/checkpoint pattern","description":"## Background\nState snapshots/checkpoints were requested but declined as a new feature because the pattern already exists via `State.Sync()`. However, this isn't documented.\n\n## What to Document\nShow users how to implement checkpointing with existing APIs:\n\n```go\n// Create state with a file adapter for persistence\nadapter := store.NewFileAdapter(\"workflow-state.json\")\nstate := workflow.NewState(adapter)\n\n// Checkpoint after expensive steps\nchain := workflow.NewChain(\"pipeline\",\n    expensiveStep1,\n    workflow.NewFuncStep(\"checkpoint-1\", func(ctx context.Context, s *workflow.State) error {\n        return s.Sync(ctx)  // Persist to file\n    }),\n    expensiveStep2,\n    workflow.NewFuncStep(\"checkpoint-2\", func(ctx context.Context, s *workflow.State) error {\n        return s.Sync(ctx)\n    }),\n)\n\n// Resume from checkpoint on restart\nstate.Reload(ctx)  // Load previous state\n```\n\n## Deliverables\n1. Add \"Checkpointing\" section to `workflow/doc.go`\n2. Create example in `cmd/demo/` showing checkpoint/resume pattern\n3. Document `StateAdapter` interface for custom persistence backends","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-18T19:25:38.318562524-08:00","updated_at":"2025-12-18T20:43:55.627546243-08:00"}
{"id":"gains-2of","title":"Consolidate Handler types into Handler[T]","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-18T20:40:31.347143627-08:00","updated_at":"2025-12-18T21:42:32.960564371-08:00","closed_at":"2025-12-18T21:42:32.960564371-08:00","close_reason":"Not applicable - Handler (type-erased for registry storage) and TypedHandler[T] (user-facing typed API) serve different architectural purposes. The registry must store type-erased handlers, while users need typed handlers for ergonomics.","dependencies":[{"issue_id":"gains-2of","depends_on_id":"gains-fcw","type":"blocks","created_at":"2025-12-18T20:57:18.652073379-08:00","created_by":"daemon"}]}
{"id":"gains-2pb","title":"Add RunAgentInput type and Prepare helper to agui package","description":"## Summary\nMove the `RunAgentInput` struct from `cmd/aguiserver/handler.go` to the `agui` package. This type represents the AG-UI protocol's request schema and is transport-agnostic - every AG-UI server implementation needs this regardless of HTTP framework.\n\n## Current State\nThe type is defined in `cmd/aguiserver/handler.go:18-28`:\n```go\ntype RunAgentInput struct {\n    ThreadID       string                `json:\"thread_id\"`\n    RunID          string                `json:\"run_id\"`\n    Messages       []aguievents.Message  `json:\"messages\"`\n    Tools          []any                 `json:\"tools,omitempty\"`\n    Context        []any                 `json:\"context,omitempty\"`\n    State          any                   `json:\"state,omitempty\"`\n    ForwardedProps any                   `json:\"forwarded_props,omitempty\"`\n}\n```\n\nThe handler then has scattered logic to validate and convert this input (lines 67-100).\n\n## Proposed API\nAdd to `agui/input.go`:\n\n```go\n// RunAgentInput represents the AG-UI protocol request for running an agent.\n// This mirrors the AG-UI protocol specification.\ntype RunAgentInput struct {\n    ThreadID       string           `json:\"thread_id\"`\n    RunID          string           `json:\"run_id\"`\n    Messages       []events.Message `json:\"messages\"`\n    Tools          []any            `json:\"tools,omitempty\"`\n    Context        []any            `json:\"context,omitempty\"`\n    State          any              `json:\"state,omitempty\"`\n    ForwardedProps any              `json:\"forwarded_props,omitempty\"`\n}\n\n// PreparedInput contains validated and converted input ready for agent execution.\ntype PreparedInput struct {\n    ThreadID  string\n    RunID     string\n    Messages  []gains.Message\n    Tools     []Tool           // Parsed frontend tools\n    ToolNames []string         // Tool names for cleanup tracking\n}\n\n// Prepare validates the input and converts it to gains types.\n// Returns an error if Messages is empty or tool parsing fails.\nfunc (r *RunAgentInput) Prepare() (*PreparedInput, error)\n```\n\n## Benefits\n1. Documents the protocol schema in the library where it belongs\n2. Consolidates validation and conversion logic in one place\n3. Makes server implementations cleaner - they focus on HTTP concerns only\n4. Enables consistent behavior across different server implementations\n5. Users don't need to re-implement the same parsing/validation\n\n## Implementation Notes\n- Move type definition to `agui/input.go`\n- Implement `Prepare()` using existing `agui.ToGainsMessages()` and `agui.ParseTools()`\n- Update `cmd/aguiserver/handler.go` to use the library type\n- Add tests for validation edge cases (empty messages, malformed tools)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T21:20:47.016824368-08:00","updated_at":"2025-12-17T21:32:35.917276123-08:00","closed_at":"2025-12-17T21:32:35.917276123-08:00","close_reason":"Closed"}
{"id":"gains-2wq","title":"Add workflow.Describe() for Mermaid visualization","description":"## Problem\nComplex workflows are hard to visualize and document. Users want to see the structure of their workflows without running them.\n\n## Solution\nAdd a `Describe()` method that outputs Mermaid diagram syntax:\n\n```go\nwf := workflow.New(\"analysis-pipeline\", \n    workflow.NewChain(\"main\",\n        setupStep,\n        workflow.NewParallel(\"research\", researchSteps, nil),\n        workflow.NewRouter(\"route\", routes, defaultRoute),\n        summarizeStep,\n    ),\n)\n\nfmt.Println(wf.Describe())\n```\n\nOutput:\n```mermaid\nflowchart TD\n    subgraph analysis-pipeline\n        setup[setup]\n        subgraph research[research - parallel]\n            research-1[scientific]\n            research-2[historical]\n            research-3[cultural]\n        end\n        route{route}\n        route --\u003e|billing| billing[billing-handler]\n        route --\u003e|technical| technical[tech-handler]\n        route --\u003e|default| general[general-handler]\n        summarize[summarize]\n        \n        setup --\u003e research\n        research --\u003e route\n        route --\u003e summarize\n    end\n```\n\n## Implementation\n1. Add `Describe() string` method to `Step` interface\n2. Implement for each step type:\n   - FuncStep: simple box\n   - PromptStep: box with LLM indicator\n   - Chain: sequential arrows\n   - Parallel: subgraph with parallel boxes\n   - Router: decision diamond with labeled arrows\n   - Loop: subgraph with back-arrow\n3. Add `Workflow.Describe()` that wraps root step\n4. Handle nested compositions recursively\n5. Add option for different output formats (Mermaid, ASCII, DOT)","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-18T19:20:37.326945556-08:00","updated_at":"2025-12-18T19:20:37.326945556-08:00"}
{"id":"gains-3db","title":"Plan comprehensive retry system revamp","description":"## Background\nThe current retry implementation lives in `internal/retry/` and is only used at the client level. Feedback suggests retry needs to work at multiple levels. Before implementing, we need a comprehensive plan.\n\n## Current State\n- `internal/retry/config.go`: Retry configuration (attempts, backoff, jitter)\n- `internal/retry/retry.go`: Core retry logic with exponential backoff\n- `client/retry.go`: Client-level retry integration\n\n## Questions to Answer\n1. **Where should retry happen?**\n   - Provider level (inside anthropic/openai/google clients)?\n   - Client level (current - wraps all provider calls)?\n   - Step level (workflow steps can retry)?\n   - All of the above?\n\n2. **What should be retryable?**\n   - HTTP 429 rate limits\n   - HTTP 5xx server errors\n   - Network timeouts\n   - Context deadline exceeded\n   - Provider-specific retryable errors\n   - Tool execution failures?\n\n3. **Configuration scope**\n   - Global defaults\n   - Per-provider overrides\n   - Per-step overrides\n   - Per-call overrides\n   - How do these compose/override?\n\n4. **Observability**\n   - Events for retry attempts?\n   - Logging hooks?\n   - Metrics integration?\n\n## Deliverable\nCreate beads epic with implementation tasks covering:\n- Retry architecture across client/agent/workflow\n- Configuration hierarchy\n- Error classification (what's retryable)\n- Event/observability integration\n- API surface changes\n- Dependency graph for implementation order\n\n## Out of Scope\n- Circuit breaker pattern (future)\n- Rate limit pre-flight checks (future)","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-18T19:21:29.973585913-08:00","updated_at":"2025-12-19T12:24:01.206603433-08:00","closed_at":"2025-12-19T12:24:01.206603433-08:00","close_reason":"Created epic gains-4w6 with 5 implementation tasks: gains-dhi (error classification), gains-62l (per-call config), gains-5bi (step retry), gains-ciz (agent retry), gains-b45 (observability)"}
{"id":"gains-3kh","title":"Add ChatTyped helper for auto-unmarshal structured output","description":"## Problem\nUsers currently do manual json.Unmarshal after WithResponseSchema:\n```go\nresp, err := c.Chat(ctx, msgs, ai.WithResponseSchema(ai.ResponseSchema{\n    Name: \"book\", Schema: ai.MustSchemaFor[BookInfo](),\n}))\nvar book BookInfo\njson.Unmarshal([]byte(resp.Content), \u0026book)\n```\n\n## Proposed Solution\n```go\nbook, err := client.ChatTyped[BookInfo](ctx, c, msgs)\n// With options\nbook, err := client.ChatTyped[BookInfo](ctx, c, msgs, ai.WithTemperature(0.5))\n```\n\n## Design Decisions\n- Package-level function (Go generics don't allow type params on methods)\n- Signature: `func ChatTyped[T any](ctx context.Context, c *Client, msgs []Message, opts ...Option) (T, error)`\n- Schema name derived from type name via reflection\n- Passes through all options to underlying Chat call\n- Related: workflow.TypedPromptStep does similar for workflows; this is standalone version","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T17:26:31.1855741-08:00","updated_at":"2025-12-17T18:02:41.2093773-08:00","closed_at":"2025-12-17T18:02:41.2093773-08:00","close_reason":"Closed"}
{"id":"gains-3pt","title":"Review and improve godoc documentation","description":"## Background\nComprehensive godoc review to ensure all public APIs are well-documented.\n\n## Scope\nReview all public packages:\n- `gains` (root) - Core types\n- `client` - Unified client\n- `agent` - Agent orchestration\n- `workflow` - Workflow patterns\n- `tool` - Tool infrastructure\n- `event` - Event types\n- `agui` - AG-UI protocol\n- `model` - Model constants\n\n## Checklist per Package\n- [ ] Package doc.go has comprehensive overview\n- [ ] All exported types have doc comments\n- [ ] All exported functions have doc comments with examples\n- [ ] Complex functions have usage examples\n- [ ] Cross-references to related types/functions\n- [ ] No broken links or outdated references\n\n## Specific Areas to Review\n1. `workflow` package - ensure all step types documented with examples\n2. `tool` package - ensure binding patterns documented\n3. `client` package - ensure option patterns documented\n4. `agent` package - ensure approval workflow documented\n\n## Deliverable\nFix all documentation gaps found during review","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-18T19:25:40.459246665-08:00","updated_at":"2025-12-18T20:43:55.534853643-08:00"}
{"id":"gains-3vo","title":"Remove Key helper functions","description":"","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-18T20:40:31.484615854-08:00","updated_at":"2025-12-19T09:39:36.89885821-08:00","closed_at":"2025-12-19T09:39:36.89885821-08:00","close_reason":"Superseded by gains-0a9 (struct-based state removes Key[T] entirely)"}
{"id":"gains-3yr","title":"Consolidate Parallel types into Parallel[T]","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-18T20:40:31.21405889-08:00","updated_at":"2025-12-18T21:45:39.706178013-08:00","closed_at":"2025-12-18T21:45:39.706178013-08:00","close_reason":"Closed"}
{"id":"gains-4hd","title":"Add type-safe Set for workflow state","description":"## Problem\nThe workflow state allows bypassing the typed Key[T] system:\n```go\nvar KeyCount = workflow.NewKey[int](\"count\")\nstate.Set(\"count\", \"not an int\")  // No compile error!\ncount := workflow.Get(state, KeyCount)  // Runtime panic or zero value\n```\n\n## Proposed Solution\nAdd typed Set function that mirrors Get:\n```go\n// Type-safe set (new)\nworkflow.Set(state, KeyCount, 42)\n// workflow.Set(state, KeyCount, \"not an int\")  // Compile error!\n\n// Signature\nfunc Set[T any](state State, key Key[T], value T)\n```\n\n## Implementation\n- Add `func Set[T any](s State, key Key[T], value T)` to workflow package\n- Deprecate raw `state.Set(string, any)` or make it internal\n- Update existing code to use typed Set","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-17T17:49:38.8508839-08:00","updated_at":"2025-12-17T18:33:59.7873733-08:00","closed_at":"2025-12-17T18:33:59.7873733-08:00","close_reason":"Set[T] already exists in typed.go. Updated state.go docs to recommend the typed Key[T] API for compile-time type safety."}
{"id":"gains-4w6","title":"Epic: Multi-level retry system","description":"","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-19T12:23:03.451172132-08:00","updated_at":"2025-12-19T12:23:03.451172132-08:00"}
{"id":"gains-4xb","title":"Unify error handling between Run and RunStream methods","description":"The `Run` and `RunStream` methods handle errors differently, violating the documented `ErrorHandler` contract and causing inconsistent behavior.\n\n## Documented Contract\n\nFrom `options.go:10-12`:\n```go\n// ErrorHandler is called when a step encounters an error.\n// Return nil to suppress the error, or return an error to propagate it.\ntype ErrorHandler func(ctx context.Context, stepName string, err error) error\n```\n\nThis implies:\n- Return `nil` → error is suppressed (handled)\n- Return `error` → that error is propagated instead of original\n\n## Current Behavior: Run Method\n\nFrom `chain.go:49-58` (Loop is identical):\n```go\nif err != nil {\n    if options.ErrorHandler != nil {\n        if handlerErr := options.ErrorHandler(ctx, step.Name(), err); handlerErr != nil {\n            return nil, \u0026StepError{StepName: step.Name(), Err: handlerErr}  // (A)\n        }\n        if options.ContinueOnError {\n            continue  // (B)\n        }\n    }\n    return nil, \u0026StepError{StepName: step.Name(), Err: err}  // (C)\n}\n```\n\n| Handler Result | ContinueOnError | Outcome |\n|----------------|-----------------|---------|\n| returns error | - | Return handler's error (A) |\n| returns nil | true | Continue to next step (B) |\n| returns nil | false | **Return ORIGINAL error (C)** ← BUG |\n| no handler | - | Return original error (C) |\n\n**Bug**: If handler returns `nil` (suppresses error) but `ContinueOnError` is false, the original error is still returned. This violates \"return nil to suppress\".\n\n## Current Behavior: RunStream Method\n\nFrom `chain.go:126-132` (Loop is identical):\n```go\nif stepError != nil {\n    if options.ErrorHandler != nil {\n        if handlerErr := options.ErrorHandler(ctx, step.Name(), stepError); handlerErr == nil \u0026\u0026 options.ContinueOnError {\n            continue  // (D)\n        }\n    }\n    return  // (E) - just stops, no error emission\n}\n```\n\n| Handler Result | ContinueOnError | Outcome |\n|----------------|-----------------|---------|\n| returns error | - | **IGNORED, just stops (E)** ← BUG |\n| returns nil | true | Continue to next step (D) |\n| returns nil | false | Just stops (E) |\n| no handler | - | Just stops (E) |\n\n**Bugs**:\n1. Handler's returned error is completely ignored\n2. No `RunError` event emitted with handler's error\n3. Workflow stops silently - caller can't distinguish \"error handled gracefully\" from \"error occurred\"\n\n## Divergence Summary\n\n| Scenario | Run | RunStream |\n|----------|-----|-----------|\n| Handler returns error | Uses handler's error ✓ | Ignores handler's error ✗ |\n| Handler returns nil, !ContinueOnError | Returns original error ✗ | Stops silently (ambiguous) |\n| Error wrapping | Wraps in StepError | No wrapping (already emitted) |\n| Error propagation | Via return value | Via event channel |\n\n## Proposed Correct Semantics\n\nThe `ErrorHandler` should work as documented:\n\n```\nError occurs\n    ↓\nCall ErrorHandler (if present)\n    ↓\nHandler returns nil? → Error is SUPPRESSED\n    ├── ContinueOnError=true  → Continue to next step\n    └── ContinueOnError=false → Stop workflow, but SUCCESS (error was handled)\n    ↓\nHandler returns error? → Error is PROPAGATED\n    └── Stop workflow with handler's error (regardless of ContinueOnError)\n    ↓\nNo handler? → Original error is PROPAGATED\n    └── Stop workflow with original error\n```\n\n## Proposed Fix\n\n### Run Method\n\n```go\nif err != nil {\n    if options.ErrorHandler != nil {\n        handlerErr := options.ErrorHandler(ctx, step.Name(), err)\n        if handlerErr != nil {\n            // Handler wants to propagate (possibly transformed) error\n            return nil, \u0026StepError{StepName: step.Name(), Err: handlerErr}\n        }\n        // Handler suppressed the error (returned nil)\n        if options.ContinueOnError {\n            continue\n        }\n        // Error suppressed, but don't continue - stop successfully\n        return \u0026StepResult{StepName: c.name, Usage: totalUsage}, nil  // SUCCESS\n    }\n    // No handler - propagate original error\n    return nil, \u0026StepError{StepName: step.Name(), Err: err}\n}\n```\n\n### RunStream Method\n\n```go\nif stepError != nil {\n    if options.ErrorHandler != nil {\n        handlerErr := options.ErrorHandler(ctx, step.Name(), stepError)\n        if handlerErr != nil {\n            // Handler wants to propagate - emit the handler's error\n            event.Emit(ch, Event{Type: event.RunError, StepName: c.name, Error: handlerErr})\n            return\n        }\n        // Handler suppressed the error\n        if options.ContinueOnError {\n            continue\n        }\n        // Error suppressed, stop successfully\n        event.Emit(ch, Event{Type: event.RunEnd, StepName: c.name})\n        return\n    }\n    // No handler - error was already emitted by step, just stop\n    return\n}\n```\n\n## Alternative: Simplify by Removing Ambiguity\n\nThe interaction between `ErrorHandler` and `ContinueOnError` is confusing. Consider:\n\n**Option A**: Remove `ContinueOnError`, let handler decide\n- Handler returns `nil` → always continue\n- Handler returns error → always stop\n- Simpler mental model\n\n**Option B**: Make `ContinueOnError` only apply when no handler\n- With handler: handler's return decides behavior\n- Without handler: `ContinueOnError` decides whether to continue or propagate\n\n**Recommendation**: Option B - it's backwards compatible and clarifies the precedence.\n\n## Files to Update\n\n- `workflow/chain.go` - Run (lines 49-58), RunStream (lines 126-132)\n- `workflow/loop.go` - Run (lines 114-123), RunStream (lines 196-202)\n- `workflow/parallel.go` - verify similar patterns\n- `workflow/options.go` - update documentation to clarify semantics\n- Tests to verify all scenarios\n\n## Test Cases Needed\n\n```go\n// Handler suppresses, ContinueOnError=false → should succeed, not return error\n// Handler suppresses, ContinueOnError=true → should continue\n// Handler returns error → should stop with handler's error\n// No handler, ContinueOnError=false → should return original error\n// No handler, ContinueOnError=true → should continue\n// RunStream should emit appropriate events for each case\n```","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-19T08:44:10.884180795-08:00","updated_at":"2025-12-19T08:44:39.992835494-08:00"}
{"id":"gains-4zt","title":"Add fluent builder API for tool Registry","description":"## Problem\nCurrent registration is repetitive for many tools:\n```go\nregistry := tool.NewRegistry()\ntool.MustRegisterFunc(registry, \"weather\", \"...\", weatherFn)\ntool.MustRegisterFunc(registry, \"search\", \"...\", searchFn)\ntool.MustRegisterFunc(registry, \"calc\", \"...\", calcFn)\n```\n\n## Proposed Solution\nFluent builder pattern:\n```go\nregistry := tool.NewRegistry().\n    Func(\"weather\", \"Get weather\", weatherFn).\n    Func(\"search\", \"Search web\", searchFn).\n    Func(\"calc\", \"Calculate\", calcFn)\n```\n\n## Design Decisions\n- Panic immediately on each .Func() call (consistent with Must* pattern)\n- No .Build() needed - chain methods return *Registry, ready to use\n- Consider additional methods: .Handler() for interface types, .Tool() for pre-built pairs","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T17:30:37.8407097-08:00","updated_at":"2025-12-17T18:09:18.6902788-08:00","closed_at":"2025-12-17T18:09:18.6902788-08:00","close_reason":"Closed"}
{"id":"gains-56m","title":"Add merge strategy options for Parallel","description":"## Problem\nCommon parallel state merge patterns require writing a full custom aggregator, which is boilerplate-heavy. Current code:\n\n```go\nparallel := workflow.NewParallel(\"steps\", steps, func(state *State, results map[string]*StepResult, errors map[string]error) error {\n    // Just want to merge specific keys\n    for _, result := range results {\n        branchState := workflow.GetBranchState(result)\n        if val, ok := workflow.Get(branchState, KeyOutput); ok {\n            // manual merge logic\n        }\n    }\n    return nil\n})\n```\n\n## Solution\nAdd merge strategy options that handle common patterns:\n\n```go\n// Merge all keys from all branches (current default)\nworkflow.NewParallel(\"steps\", steps, nil) // or explicit:\nworkflow.NewParallel(\"steps\", steps, workflow.MergeAll())\n\n// Merge only specific keys\nworkflow.NewParallel(\"steps\", steps, workflow.MergeKeys(\"output\", \"metadata\"))\n\n// Type-safe key merge\nworkflow.NewParallel(\"steps\", steps, workflow.MergeTypedKeys(KeyOutput, KeyMetadata))\n\n// Collect values from all branches into a slice under a single key\nworkflow.NewParallel(\"steps\", steps, workflow.CollectInto[string](KeyResults))\n```\n\n## Implementation\n1. Add `MergeStrategy` interface or function type\n2. Implement `MergeAll()` - current default behavior\n3. Implement `MergeKeys(keys ...string)` - merge only named keys\n4. Implement `MergeTypedKeys[T](keys ...Key[T])` - type-safe variant\n5. Implement `CollectInto[T](key Key[[]T])` - collect branch values into slice\n6. Update Parallel to accept either Aggregator or MergeStrategy\n7. Add tests and documentation","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-18T19:17:54.767987783-08:00","updated_at":"2025-12-18T20:01:20.476760008-08:00","closed_at":"2025-12-18T20:01:20.476760008-08:00","close_reason":"Closed"}
{"id":"gains-5bi","title":"Workflow step retry wrapper","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T12:23:36.004351528-08:00","updated_at":"2025-12-19T12:23:36.004351528-08:00","dependencies":[{"issue_id":"gains-5bi","depends_on_id":"gains-dhi","type":"blocks","created_at":"2025-12-19T12:23:45.600418123-08:00","created_by":"daemon"}]}
{"id":"gains-5o9","title":"Add GetFromBranch helper for parallel state access","description":"## Problem\nWhen using Parallel with a custom aggregator, branch states are buried in `result.Metadata[\"branch_state\"]`. Users must manually fish out typed values:\n\n```go\naggregator := func(state *State, results map[string]*StepResult) error {\n    for name, result := range results {\n        if branchState, ok := result.Metadata[\"branch_state\"].(*State); ok {\n            // Manually extract what we need\n            riff := workflow.MustGet(branchState, KeyRiff)\n        }\n    }\n}\n```\n\n## Solution\nAdd typed helper functions:\n\n```go\n// GetFromBranch extracts a typed value from a branch's state within StepResult\nfunc GetFromBranch[T any](result *StepResult, key Key[T]) (T, bool)\n\n// MustGetFromBranch panics if key not found or type mismatch\nfunc MustGetFromBranch[T any](result *StepResult, key Key[T]) T\n\n// GetBranchState extracts the full branch state from a result\nfunc GetBranchState(result *StepResult) (*State, bool)\n```\n\nUsage becomes:\n```go\naggregator := func(state *State, results map[string]*StepResult) error {\n    for name, result := range results {\n        riff := workflow.MustGetFromBranch(result, KeyRiff)\n    }\n}\n```\n\n## Implementation\n1. Add helpers to `workflow/typed.go`\n2. Add tests\n3. Document in `workflow/doc.go` Parallel section","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-18T19:16:37.992360052-08:00","updated_at":"2025-12-18T19:42:57.961042304-08:00","closed_at":"2025-12-18T19:42:57.961042304-08:00","close_reason":"Closed"}
{"id":"gains-62l","title":"Per-call retry config option","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T12:23:35.903877061-08:00","updated_at":"2025-12-19T12:23:35.903877061-08:00","dependencies":[{"issue_id":"gains-62l","depends_on_id":"gains-dhi","type":"blocks","created_at":"2025-12-19T12:23:45.524901721-08:00","created_by":"daemon"}]}
{"id":"gains-64z","title":"Update docs/workflow.md after workflow improvements","description":"## Background\nAfter completing the workflow improvement tasks, the documentation in `docs/` needs to be updated to reflect new features.\n\n## Prerequisites\nThis task should be done AFTER:\n- gains-5o9: GetFromBranch helper\n- gains-9as: Parallel error visibility\n- gains-56m: Merge strategy options\n- gains-8b7: TypedParallel (if completed)\n\n## Updates Needed\n1. **Parallel section**: Document new features\n   - GetFromBranch helper usage\n   - New Aggregator signature with errors parameter\n   - MergeStrategy options (MergeAll, MergeKeys, CollectInto)\n   - TypedParallel usage (if implemented)\n\n2. **Error handling section**: Document parallel error visibility\n   - How errors are passed to aggregator\n   - StepSkipped events in ContinueOnError mode\n\n3. **Examples**: Update or add examples showing new patterns\n\n## Deliverable\nUpdated `docs/workflow.md` with comprehensive documentation of new workflow features","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-18T19:25:42.429062136-08:00","updated_at":"2025-12-18T20:11:53.281445582-08:00","closed_at":"2025-12-18T20:11:53.281445582-08:00","close_reason":"Closed","dependencies":[{"issue_id":"gains-64z","depends_on_id":"gains-5o9","type":"blocks","created_at":"2025-12-18T19:25:51.732005545-08:00","created_by":"daemon"},{"issue_id":"gains-64z","depends_on_id":"gains-9as","type":"blocks","created_at":"2025-12-18T19:25:51.830561758-08:00","created_by":"daemon"},{"issue_id":"gains-64z","depends_on_id":"gains-56m","type":"blocks","created_at":"2025-12-18T19:25:51.92675764-08:00","created_by":"daemon"}]}
{"id":"gains-8b7","title":"Add TypedParallel for homogeneous branches","description":"## Problem\nWhen running parallel branches that all produce the same type (e.g., analyzing chunks), the current pattern requires a custom aggregator with type assertions:\n\n```go\nparallel := workflow.NewParallel(\"riffs\", steps, func(state *State, results map[string]*StepResult, errors map[string]error) error {\n    var riffs []Riff\n    for _, result := range results {\n        if riff, ok := workflow.GetFromBranch(result, KeyRiff); ok {\n            riffs = append(riffs, riff)\n        }\n    }\n    workflow.Set(state, KeyAllRiffs, riffs)\n    return nil\n})\n```\n\n## Solution\nAdd `TypedParallel[T]` for homogeneous branches:\n\n```go\n// All branches produce type T, collected into []T\ntype TypedParallel[T any] struct {\n    name      string\n    steps     []Step\n    outputKey Key[[]T]\n    inputKey  Key[T]  // Key each branch writes to\n}\n\n// Usage\nparallel := workflow.NewTypedParallel[Riff](\n    \"riffs\",\n    steps,\n    KeyRiff,        // Each branch writes here\n    KeyAllRiffs,    // Collected results go here\n)\n\n// After execution: state has KeyAllRiffs = []Riff{...}\n```\n\nCan also support a typed aggregator for custom combination logic:\n\n```go\nworkflow.NewTypedParallelWithAggregator[Riff, Summary](\n    \"riffs\",\n    steps,\n    KeyRiff,\n    func(results []Riff) Summary { return combineRiffs(results) },\n    KeySummary,\n)\n```\n\n## Implementation\n1. Add `TypedParallel[T]` struct to `workflow/typed.go`\n2. Implement `NewTypedParallel[T]` constructor\n3. Implement `NewTypedParallelWithAggregator[T, U]` variant\n4. Run/RunStream automatically collect typed results\n5. Handle errors consistently with regular Parallel\n6. Add tests and examples","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-18T19:19:50.217986444-08:00","updated_at":"2025-12-18T20:04:09.827841759-08:00","closed_at":"2025-12-18T20:04:09.827841759-08:00","close_reason":"Closed"}
{"id":"gains-9as","title":"Improve parallel step error visibility","description":"## Problem\nWhen `ContinueOnError=true`, parallel step errors go into a map but the aggregator only receives successful results. Users have no visibility into which steps failed or why.\n\n## Current Behavior\n```go\n// In parallel.go:96-104\nif len(errors) \u003e 0 \u0026\u0026 !options.ContinueOnError {\n    return nil, \u0026ParallelError{Errors: errors}\n}\n// Aggregator only gets successful results\nif p.aggregator != nil {\n    p.aggregator(state, results)  // No error info passed!\n}\n```\n\n## Solution\nChange the Aggregator type signature to include errors:\n\n```go\n// Old:\ntype Aggregator func(state *State, results map[string]*StepResult) error\n\n// New:\ntype Aggregator func(state *State, results map[string]*StepResult, errors map[string]error) error\n```\n\nThis gives aggregators full visibility into what succeeded and what failed.\n\nAdditionally, emit warning events when steps fail in ContinueOnError mode so streaming consumers have visibility:\n```go\nevent.Emit(ch, Event{Type: event.StepSkipped, StepName: s.Name(), Error: err, Message: \"step failed, continuing\"})\n```\n\n## Implementation\n1. Update Aggregator type signature\n2. Update all call sites to pass errors map\n3. Emit StepSkipped events on failures when ContinueOnError=true  \n4. Update demo and docs","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-18T19:17:18.208541399-08:00","updated_at":"2025-12-18T19:53:10.137498898-08:00","closed_at":"2025-12-18T19:53:10.137498898-08:00","close_reason":"Closed"}
{"id":"gains-b45","title":"Retry observability events","description":"","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-19T12:23:36.226618188-08:00","updated_at":"2025-12-19T12:23:36.226618188-08:00","dependencies":[{"issue_id":"gains-b45","depends_on_id":"gains-5bi","type":"blocks","created_at":"2025-12-19T12:23:45.707798036-08:00","created_by":"daemon"},{"issue_id":"gains-b45","depends_on_id":"gains-ciz","type":"blocks","created_at":"2025-12-19T12:23:45.777771635-08:00","created_by":"daemon"}]}
{"id":"gains-bg5","title":"Remove unused TypedStore[T]","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T20:40:30.332095948-08:00","updated_at":"2025-12-18T20:46:19.3498877-08:00","closed_at":"2025-12-18T20:46:19.3498877-08:00","close_reason":"Closed"}
{"id":"gains-bw2","title":"Add struct-based state initialization","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-18T22:27:13.689582674-08:00","updated_at":"2025-12-18T22:30:18.713057503-08:00","closed_at":"2025-12-18T22:30:18.713057503-08:00","close_reason":"Closed"}
{"id":"gains-ciz","title":"Agent step retry","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T12:23:36.11631597-08:00","updated_at":"2025-12-19T12:23:36.11631597-08:00","dependencies":[{"issue_id":"gains-ciz","depends_on_id":"gains-dhi","type":"blocks","created_at":"2025-12-19T12:23:45.649934678-08:00","created_by":"daemon"}]}
{"id":"gains-cvc","title":"Consolidate PromptStep and TypedPromptStep[T] into PromptStep[T]","description":"Remove `PromptStep` (untyped) and `TypedPromptStep[T]`, replacing both with a single `PromptStep[T]` that handles both plain text and structured output based on whether a schema is provided.\n\n## Motivation\n\nThis follows the pattern established in recent refactors:\n- `refactor(workflow): remove TypedParallel types`\n- `refactor(workflow): remove WithKey constructor variants`\n- `refactor(workflow): consolidate Loop constructors to typed-only API`\n\nCurrently we have two types with nearly identical implementations:\n- `PromptStep` - stores `string` at outputKey\n- `TypedPromptStep[T]` - stores `*T` at outputKey, requires schema\n\nThis creates:\n1. **Inconsistent output types** - downstream steps must know which type was used\n2. **Larger API surface** - two types to learn instead of one\n3. **Code duplication** - Run/RunStream logic is ~90% identical\n\n## Design\n\n### Single Type with Optional Schema\n\n```go\ntype PromptStep[T any] struct {\n    name       string\n    chatClient chat.Client\n    prompt     PromptFunc\n    outputKey  string\n    chatOpts   []ai.Option\n    schema     *ai.ResponseSchema  // nil for plain text\n}\n```\n\n### Single Constructor with Pointer Schema\n\n```go\nfunc NewPromptStep[T any](\n    name string,\n    c chat.Client,\n    prompt PromptFunc,\n    schema *ai.ResponseSchema,  // nil for plain text, non-nil for structured\n    outputKey string,\n    opts ...ai.Option,\n) *PromptStep[T]\n```\n\n### Usage Patterns\n\n```go\n// Plain text output\nstep := NewPromptStep[string](\"summarize\", client, prompt, nil, \"summary\")\n// After execution: state contains \"summary\" -\u003e string\n\n// Structured output\nstep := NewPromptStep[Analysis](\"analyze\", client, prompt, \u0026schema, \"result\")\n// After execution: state contains \"result\" -\u003e *Analysis\n```\n\n### Behavioral Rules\n\n| Schema | Action | Stores |\n|--------|--------|--------|\n| `nil` | No `WithResponseSchema` added, store `resp.Content` directly | `string` |\n| `non-nil` | Add `WithResponseSchema`, unmarshal JSON to T | `*T` |\n\n### Run Implementation Sketch\n\n```go\nfunc (p *PromptStep[T]) Run(ctx context.Context, state *State, opts ...Option) (*StepResult, error) {\n    options := ApplyOptions(opts...)\n    chatOpts := mergeOptions(p.chatOpts, options.ChatOptions)\n    \n    if p.schema != nil {\n        chatOpts = append(chatOpts, ai.WithResponseSchema(*p.schema))\n    }\n    \n    msgs := p.prompt(state)\n    resp, err := p.chatClient.Chat(ctx, msgs, chatOpts...)\n    if err != nil {\n        return nil, err\n    }\n    \n    if p.schema == nil {\n        // Plain text mode\n        if p.outputKey != \"\" {\n            state.Set(p.outputKey, resp.Content)\n        }\n        return \u0026StepResult{\n            StepName: p.name,\n            Output:   resp.Content,\n            Response: resp,\n            Usage:    resp.Usage,\n        }, nil\n    }\n    \n    // Structured output mode\n    var result T\n    if err := json.Unmarshal([]byte(resp.Content), \u0026result); err != nil {\n        return nil, \u0026ai.UnmarshalError{\n            Context:    fmt.Sprintf(\"workflow: step %q\", p.name),\n            Content:    resp.Content,\n            TargetType: fmt.Sprintf(\"%T\", result),\n            Err:        err,\n        }\n    }\n    \n    if p.outputKey != \"\" {\n        state.Set(p.outputKey, \u0026result)\n    }\n    return \u0026StepResult{\n        StepName: p.name,\n        Output:   \u0026result,\n        Response: resp,\n        Usage:    resp.Usage,\n    }, nil\n}\n```\n\n## Changes Required\n\n### workflow/step.go\n\n1. Delete `PromptStep` struct (lines 79-85)\n2. Delete `NewPromptStep` constructor (lines 87-98)\n3. Delete `PromptStep.Name()` method (line 101)\n4. Delete `PromptStep.Run()` method (lines 103-128)\n5. Delete `PromptStep.RunStream()` method (lines 130-181)\n6. Rename `TypedPromptStep[T]` → `PromptStep[T]`\n7. Rename `NewTypedPromptStep[T]` → `NewPromptStep[T]`\n8. Change `schema ai.ResponseSchema` → `schema *ai.ResponseSchema`\n9. Update `Run()` to handle nil schema (plain text) case\n10. Update `RunStream()` to handle nil schema (plain text) case\n11. Update godoc comments and examples\n\n### Tests\n\nUpdate any tests that use old constructors:\n- `NewPromptStep(...)` → `NewPromptStep[string](..., nil, ...)`\n- `NewTypedPromptStep[T](...)` → `NewPromptStep[T](..., \u0026schema, ...)`\n\n### Demos/Examples\n\nUpdate any demo code using old API.\n\n## Migration Guide\n\n| Before | After |\n|--------|-------|\n| `NewPromptStep(name, client, prompt, key, opts...)` | `NewPromptStep[string](name, client, prompt, nil, key, opts...)` |\n| `NewTypedPromptStep[T](name, client, prompt, schema, key, opts...)` | `NewPromptStep[T](name, client, prompt, \u0026schema, key, opts...)` |\n\n## Edge Cases\n\n**User creates `NewPromptStep[MyStruct](..., nil, ...)`:**\n- No schema sent to LLM, plain text returned\n- String stored in state\n- When read with `Get[*MyStruct]`, type assertion fails\n- This is a programming error - acceptable failure mode\n\n## Code Savings\n\n- Removes ~100 lines of duplicate code\n- Removes one exported type\n- Simplifies mental model\n\n## File\n\n`workflow/step.go`","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T08:33:29.594712621-08:00","updated_at":"2025-12-19T11:13:25.004547909-08:00","closed_at":"2025-12-19T11:13:25.004547909-08:00","close_reason":"Implemented in commit 96a0db7","dependencies":[{"issue_id":"gains-cvc","depends_on_id":"gains-0a9","type":"blocks","created_at":"2025-12-19T09:23:28.336710333-08:00","created_by":"daemon"}]}
{"id":"gains-d62","title":"Add unified error handling with categories","description":"## Problem\nErrors are inconsistent across packages. No standard way to know if an error is retryable or what action to take.\n\n## Proposed Solution\n```go\n// In gains/errors.go\ntype ErrorCategory string\nconst (\n    ErrorTransient  ErrorCategory = \"transient\"  // retry-able\n    ErrorPermanent  ErrorCategory = \"permanent\"  // don't retry\n    ErrorUserInput  ErrorCategory = \"user_input\" // user must fix\n)\n\ntype CategorizedError interface {\n    error\n    Category() ErrorCategory\n    Retryable() bool           // convenience (Category == Transient)\n    StatusCode() int           // HTTP status if applicable (0 if not)\n    RetryAfter() time.Duration // from header if available (0 if not)\n}\n\n// Helper functions\nfunc IsTransient(err error) bool\nfunc IsPermanent(err error) bool\nfunc IsUserInput(err error) bool\n```\n\n## Design Decisions\n- Interface-based for flexibility (any error can implement it)\n- Include metadata: StatusCode, RetryAfter for richer error handling\n- Helper functions to check category without type assertion\n- Integrate with internal/retry package - only retry transient errors\n- Wrap provider SDK errors with appropriate categories:\n  - 429 Rate Limit → transient\n  - 401 Unauthorized → permanent  \n  - 400 Bad Request → user_input","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T17:35:17.5175731-08:00","updated_at":"2025-12-17T18:28:45.9383285-08:00","closed_at":"2025-12-17T18:28:45.9383285-08:00","close_reason":"Closed"}
{"id":"gains-dhi","title":"Retry error classification and interface","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T12:23:35.79960635-08:00","updated_at":"2025-12-19T12:23:35.79960635-08:00"}
{"id":"gains-e5o","title":"Remove WithKey constructor variants","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-18T20:40:30.913450567-08:00","updated_at":"2025-12-18T21:41:18.691277609-08:00","closed_at":"2025-12-18T21:41:18.691277609-08:00","close_reason":"Closed","dependencies":[{"issue_id":"gains-e5o","depends_on_id":"gains-xyy","type":"blocks","created_at":"2025-12-18T20:40:44.529128279-08:00","created_by":"daemon"},{"issue_id":"gains-e5o","depends_on_id":"gains-g2i","type":"blocks","created_at":"2025-12-18T20:40:44.619359595-08:00","created_by":"daemon"}]}
{"id":"gains-es9","title":"Rethink agent as native workflow pattern","description":"## Problem\nCurrent architecture has agent as a separate package that workflow wraps via AgentStep. This creates:\n- Adapter complexity (ChatClient interfaces, event mapping)\n- Two mental models (agent vs workflow)\n- AgentStep feels bolted-on rather than native\n\n## Key Insight\nAn autonomous agent IS a workflow pattern. Like Chain, Parallel, Router, Loop - agent is fundamentally:\n```\nLoop(\n  PromptStep -\u003e ToolExecutionStep,\n  until: no tool calls or max steps\n)\n```\n\nA \"standard autonomous agent\" is just a workflow with one agent step.\n\n## Questions to Explore\n1. Can agent become a native workflow primitive (like Loop)?\n2. Should workflow subsume agent entirely?\n3. What's the minimal interface for tool-calling within workflow?\n4. How do approval workflows fit in?\n\n## Blocked\nIntentionally blocked for design rethinking. Previous implementation attempts added unwanted adapter complexity.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T17:32:21.7698258-08:00","updated_at":"2025-12-17T18:50:54.3804986-08:00","closed_at":"2025-12-17T18:50:54.3804986-08:00","close_reason":"## Analysis Complete\n\n**Decision: Keep current architecture. AgentStep adapter is the right level of abstraction.**\n\n### Key Findings\n\n1. **Agent should NOT become a native workflow primitive**\n   - Agent has unique semantics: internal tool-loop, approval mid-execution, termination logic\n   - Making it native would conflate \"autonomous tool-calling\" with \"step orchestration\"\n\n2. **Workflow should NOT subsume agent**\n   - Different purposes: Agent = autonomous, Workflow = composable patterns\n   - Agent is correctly a \"black box\" step\n   - Backward compatibility matters\n\n3. **Minimal tool-calling interface already exists**\n   - ToolStep for deterministic single-tool execution\n   - AgentStep for LLM-orchestrated tool use\n   - Compose with Chain/Parallel/Router for complex flows\n\n4. **Approval belongs in agent** (mid-loop, before tool execution)\n\n### On \"Adapter Complexity\"\n\nThe AgentStep.RunStream() mapping (120+ lines) is verbose but mechanical. The agent and workflow event systems are nearly identical - the adapter just adds StepName and reconstructs message history.\n\nThis is acceptable overhead for clean separation of concerns. The alternative (merging packages) would create more problems than it solves.\n\n### Recommendation\n\nNo changes needed. Document when to use:\n- `ToolStep`: Deterministic, programmatic tool execution\n- `AgentStep`: Autonomous, LLM-decides tool execution"}
{"id":"gains-fcw","title":"Create chat package and restructure core types","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-18T20:56:42.753797184-08:00","updated_at":"2025-12-18T21:09:38.734052799-08:00","closed_at":"2025-12-18T21:09:38.734052799-08:00","close_reason":"Closed"}
{"id":"gains-g2i","title":"Consolidate PromptStep and TypedPromptStep into PromptStep[T]","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-18T20:40:30.622441012-08:00","updated_at":"2025-12-18T21:12:45.832219939-08:00","closed_at":"2025-12-18T21:12:45.832219939-08:00","close_reason":"PromptStep (free-form text) and TypedPromptStep (structured JSON) serve fundamentally different purposes - not redundant","dependencies":[{"issue_id":"gains-g2i","depends_on_id":"gains-fcw","type":"blocks","created_at":"2025-12-18T20:57:18.583213027-08:00","created_by":"daemon"}]}
{"id":"gains-g3q","title":"Consolidate UnmarshalError types","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-18T20:40:31.05353409-08:00","updated_at":"2025-12-18T21:38:07.575551852-08:00","closed_at":"2025-12-18T21:38:07.575551852-08:00","close_reason":"Closed","dependencies":[{"issue_id":"gains-g3q","depends_on_id":"gains-fcw","type":"blocks","created_at":"2025-12-18T20:57:18.70918077-08:00","created_by":"daemon"}]}
{"id":"gains-gre","title":"Unify ChatClient interface across packages","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T20:40:30.49824083-08:00","updated_at":"2025-12-18T20:54:03.073156568-08:00","closed_at":"2025-12-18T20:54:03.073156568-08:00","close_reason":"Closed"}
{"id":"gains-gw7","title":"PromptStep[S,T] with field getter and optional schema","description":"Simplify PromptStep API by combining schema and field destination.\n\n## Current API (setter receives string)\n```go\nstep := NewPromptStep[MyState](\"analyze\", client, promptFn,\n    func(s *MyState, content string) {\n        json.Unmarshal([]byte(content), \u0026s.Analysis)\n    },\n    ai.WithResponseSchema(schema),\n)\n```\n\n## New API (field getter + optional schema)\n```go\n// Structured output\nstep := NewPromptStep[MyState, Analysis](\"analyze\", client, promptFn, schema,\n    func(s *MyState) *Analysis { return \u0026s.Analysis },\n)\n\n// Plain text\nstep := NewPromptStep[MyState, string](\"summarize\", client, promptFn, nil,\n    func(s *MyState) *string { return \u0026s.Summary },\n)\n```\n\n## Implementation\n\n```go\ntype PromptStep[S, T any] struct {\n    name       string\n    chatClient chat.Client\n    prompt     PromptFunc[S]\n    schema     *ai.ResponseSchema  // nil for plain text\n    field      func(*S) *T         // returns pointer to field\n    chatOpts   []ai.Option\n}\n\nfunc NewPromptStep[S, T any](\n    name string,\n    c chat.Client,\n    prompt PromptFunc[S],\n    schema *ai.ResponseSchema,\n    field func(*S) *T,\n    opts ...ai.Option,\n) *PromptStep[S, T]\n\nfunc (p *PromptStep[S, T]) Run(ctx context.Context, state *S, opts ...Option) error {\n    // ... chat call with schema if non-nil ...\n    \n    if p.field != nil {\n        if p.schema != nil {\n            // Structured: unmarshal JSON\n            if err := json.Unmarshal([]byte(resp.Content), p.field(state)); err != nil {\n                return \u0026UnmarshalError{Content: resp.Content, Err: err}\n            }\n        } else {\n            // Plain text: direct string assign\n            if strPtr, ok := any(p.field(state)).(*string); ok {\n                *strPtr = resp.Content\n            } else {\n                return fmt.Errorf(\"no schema requires string field, got %T\", p.field(state))\n            }\n        }\n    }\n    return nil\n}\n```\n\n## Behavior\n\n| schema | T | Action |\n|--------|---|--------|\n| non-nil | any | Add WithResponseSchema, unmarshal JSON to *T |\n| nil | string | Direct assign resp.Content to *string |\n| nil | non-string | Runtime error |\n\n## Changes\n\n- workflow/step.go: Update PromptStep to [S, T], field getter, schema param\n- workflow/*_test.go: Update tests\n- cmd/demo/*: Update demos\n\n## Benefits\n\n- No manual json.Unmarshal in user code\n- Schema and destination are coupled (always need both)\n- Type-safe field access\n- Uniform API for string and structured output","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T11:31:16.680330263-08:00","updated_at":"2025-12-19T11:44:01.950039213-08:00","closed_at":"2025-12-19T11:44:01.950039213-08:00","close_reason":"Implemented in commit 475d7d7"}
{"id":"gains-hky","title":"Add cost calculation helpers","description":"## Problem\nThe library has `model.ChatPricing` with pricing data and tracks `Usage` on responses, but there's no easy way to calculate actual cost. Users can't answer \"how much did this workflow cost?\"\n\n## Current State\n```go\n// model/pricing.go has pricing\ntype ChatPricing struct {\n    InputPerMillion  float64\n    OutputPerMillion float64\n    // ...\n}\n\n// workflow/event.go tracks usage\ntype Result struct {\n    Usage ai.Usage  // Has InputTokens, OutputTokens\n}\n\n// But no way to calculate cost\n```\n\n## Solution\nAdd cost calculation helpers:\n\n```go\n// On ChatModel\nfunc (m ChatModel) Cost(usage ai.Usage) float64 {\n    pricing := m.Pricing()\n    return (float64(usage.InputTokens) * pricing.InputPerMillion / 1_000_000) +\n           (float64(usage.OutputTokens) * pricing.OutputPerMillion / 1_000_000)\n}\n\n// On workflow.Result\nfunc (r *Result) TotalCost(model ai.Model) float64 {\n    return model.Cost(r.Usage)\n}\n\n// Convenience for mixed-model workflows\nfunc CalculateCost(usage ai.Usage, pricing model.ChatPricing) float64\n```\n\n## Implementation\n1. Add `Cost(usage Usage) float64` method to `model.ChatModel`\n2. Add `TotalCost(model Model) float64` method to `workflow.Result`\n3. Add standalone `CalculateCost` for flexibility\n4. Handle edge cases (long context pricing for Google, cached tokens for OpenAI)\n5. Add tests with known pricing\n6. Document usage patterns","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-18T19:17:58.470876766-08:00","updated_at":"2025-12-18T19:57:59.673692292-08:00","closed_at":"2025-12-18T19:57:59.673692292-08:00","close_reason":"Closed"}
{"id":"gains-idz","title":"Add ChatOnce helper for single-turn chat","description":"## Problem\nCurrently the simplest chat requires ~8 lines:\n```go\nc := client.New(client.Config{...})\nresp, err := c.Chat(ctx, []ai.Message{{Role: ai.RoleUser, Content: \"Hello\"}})\n```\n\n## Proposed Solution\nAdd a one-liner helper:\n```go\nresp, err := client.ChatOnce(ctx, \"Hello\", client.WithAPIKey(key), ai.WithModel(model.ClaudeSonnet45))\n```\n\n## Design Decision\n**Approach A**: Support tools via ai.WithTools() but don't execute them automatically. Returns response with ToolCalls if model requests them; caller handles execution. Keeps it simple and predictable.\n\n## Implementation Notes\n- Package-level function in client package\n- Creates ephemeral client internally\n- Supports all ai.Option types\n- Provider selected based on model option\n- No tool execution loop (use agent.Agent for that)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T17:18:54.7290718-08:00","updated_at":"2025-12-17T17:59:49.3141819-08:00","closed_at":"2025-12-17T17:59:49.3141819-08:00","close_reason":"wontfix"}
{"id":"gains-im0","title":"Simplify Step API: Run() returns error only, remove T type parameter","description":"Simplify the workflow Step API based on the insight that state mutation is the only communication mechanism.\n\n## Final Step interface\n```go\ntype Step[S any] interface {\n    Name() string\n    Run(ctx context.Context, state *S, opts ...Option) error\n    RunStream(ctx context.Context, state *S, opts ...Option) \u003c-chan Event\n}\n```\n\n## All steps use single type parameter S\n- `PromptStep[S]` - setter receives `string` (response content)\n- `FuncStep[S]` - no setter, mutates state directly\n- `ToolStep[S]` - setter receives `string` (tool result)\n- `AgentStep[S]` - setter receives `*AgentResult` (full result with steps, termination, messages)\n\n## Changes\n\n### 1. Run() returns error only\nState is passed as pointer, mutated in place. Caller already has final state.\n\n### 2. Remove T type parameter from PromptStep\n```go\n// Before\nNewPromptStep[MyState, Analysis](\"analyze\", c, promptFn, schema,\n    func(s *MyState, result *Analysis) { s.Analysis = result },\n)\n\n// After  \nNewPromptStep[MyState](\"analyze\", c, promptFn,\n    func(s *MyState, content string) {\n        json.Unmarshal([]byte(content), \u0026s.Analysis)\n    },\n    ai.WithResponseSchema(schema),\n)\n```\n\n### 3. Remove T type parameter from ToolStep\n```go\n// Before\nNewToolStep[MyState, LookupArgs](\"lookup\", registry, \"lookup\",\n    func(s *MyState) (LookupArgs, error) { return LookupArgs{Key: s.Key}, nil },\n    func(s *MyState, r *ToolStepOutput[LookupArgs]) { s.Result = r.Result },\n)\n\n// After\nNewToolStep[MyState](\"lookup\", registry, \"lookup\",\n    func(s *MyState) (any, error) { return LookupArgs{Key: s.Key}, nil },\n    func(s *MyState, result string) { s.Result = result },\n)\n```\n\n### 4. AgentStep setter receives full result\n```go\nNewAgentStep[MyState](\"solver\", c, registry, promptFn,\n    func(s *MyState, r *AgentResult) {\n        s.AgentResult = r  // has Steps, Termination, Messages, Response\n    },\n    agent.WithMaxSteps(5),\n)\n```\n\n### 5. Remove StepResult entirely\nOutput stored in state. Metadata available via streaming events only.\n\n### 6. Remove Dependencies()\nYAGNI - Go's type system validates at compile time.\n\n## Files to update\n- workflow/step.go (Step interface, PromptStep, FuncStep)\n- workflow/tool_step.go (remove ToolStepOutput[T])\n- workflow/agent_step.go\n- workflow/chain.go\n- workflow/parallel.go\n- workflow/router.go\n- workflow/loop.go\n- workflow/workflow.go\n- workflow/event.go (remove Result[S])\n- All tests and demos","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-19T10:33:43.267581017-08:00","updated_at":"2025-12-19T11:13:24.946080011-08:00","closed_at":"2025-12-19T11:13:24.946080011-08:00","close_reason":"Implemented in commit 96a0db7"}
{"id":"gains-k3g","title":"Remove tools-in-basic-Chat demo and docs","description":"## Context\nAfter review, tools in basic Chat has no coherent use case that isn't better served by:\n- Agent (for tool execution, even single-step with WithMaxSteps(1))\n- ChatTyped (for structured output)\n\nThe current demo teaches a pattern nobody should use in production.\n\n## Changes\n1. Remove cmd/demo/tools.go (manual two-round tool loop example)\n2. Update README to not show tools with basic Chat\n3. Update any godoc that suggests using WithTools directly\n4. Keep WithTools public (Agent uses it internally) but don't document for direct use\n\n## Files to Review\n- cmd/demo/tools.go - DELETE\n- README.md - remove tool examples with basic Chat\n- doc.go - update if needed\n- options.go godoc - consider noting 'used internally by Agent'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T17:45:57.657638-08:00","updated_at":"2025-12-17T18:32:07.0076683-08:00","closed_at":"2025-12-17T18:32:07.0076683-08:00","close_reason":"Closed"}
{"id":"gains-l69","title":"Remove string-based Loop constructors, rename typed versions","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-18T20:40:30.777252071-08:00","updated_at":"2025-12-18T21:34:11.245859224-08:00","closed_at":"2025-12-18T21:34:11.245859224-08:00","close_reason":"Closed"}
{"id":"gains-mog","title":"Change default step timeout from 30s to 2m","description":"The current default step timeout of 30 seconds is too short for many LLM operations. Increase to 2 minutes to provide more headroom for longer-running steps.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-18T19:00:29.241245054-08:00","updated_at":"2025-12-18T19:54:45.976780855-08:00","closed_at":"2025-12-18T19:54:45.976780855-08:00","close_reason":"Closed"}
{"id":"gains-ppl","title":"Add Mapper.MapStream helper for filtered event streaming","description":"## Summary\nAdd a convenience method to `agui.Mapper` that wraps a gains event channel and yields only non-nil AG-UI events. This encapsulates the common streaming pattern used in every AG-UI server.\n\n## Current State\nEvery AG-UI server implementation must write this same loop:\n\n```go\nmapper := agui.NewMapper(threadID, runID)\nfor ev := range agent.RunStream(ctx, messages) {\n    aguiEvent := mapper.MapEvent(ev)\n    if aguiEvent == nil {\n        continue // Skip events with no AG-UI equivalent\n    }\n    writeEvent(aguiEvent)  // transport-specific\n}\n```\n\n## Proposed API\nAdd to `agui/mapper.go`:\n\n```go\n// MapStream wraps a gains event channel and yields AG-UI events.\n// Events that have no AG-UI equivalent (returning nil from MapEvent) are filtered out.\n// The returned channel closes when the input channel closes.\nfunc (m *Mapper) MapStream(events \u003c-chan event.Event) \u003c-chan events.Event\n```\n\n## Usage Example\n```go\nmapper := agui.NewMapper(threadID, runID)\n\n// User handles transport-specific writing\nfor aguiEvent := range mapper.MapStream(agent.RunStream(ctx, messages)) {\n    writeSSE(w, aguiEvent)  // or websocket, or whatever transport\n}\n```\n\n## Benefits\n1. Reduces boilerplate in every server implementation\n2. Encapsulates the nil-filtering logic\n3. Cleaner separation: library handles event mapping, user handles transport\n4. Less room for errors (forgetting the nil check)\n\n## Implementation Notes\n- Spawn a goroutine that reads from input, maps, filters nils, writes to output\n- Close output channel when input closes\n- Consider if context cancellation should be supported (probably via input channel closing)\n- Add tests verifying nil events are filtered\n- Update `cmd/aguiserver/handler.go` to use the new helper","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T21:26:51.990154624-08:00","updated_at":"2025-12-17T21:36:35.010715026-08:00","closed_at":"2025-12-17T21:36:35.010715026-08:00","close_reason":"Implemented MapStream helper in agui/mapper.go with tests, updated aguiserver handler to use it"}
{"id":"gains-vos","title":"Add DeepClone to Store and use in Parallel","description":"Add `DeepClone()` method to `store.Store` and update `workflow.Parallel` to use it, preventing unintended state mutations across branches.\n\n## Problem\n\n`Store.Clone()` (line 150-158) creates a shallow copy:\n\n```go\nfunc (s *Store) Clone() *Store {\n    clone := New(nil)\n    for k, v := range s.cache {\n        clone.cache[k] = v  // copies pointer, not value\n    }\n    return clone\n}\n```\n\nWhen Parallel runs branches (`parallel.go:69`, `parallel.go:171`), each branch gets `state.Clone()`. If state contains pointers, slices, or maps, mutations in one branch affect all others:\n\n```go\n// State contains: \"items\" -\u003e []string{\"a\", \"b\"}\nparallel := NewParallel(\"process\",\n    NewFuncStep(\"branch1\", func(ctx context.Context, s *State) error {\n        items := s.Get(\"items\").([]string)\n        items[0] = \"modified\"  // Mutates shared slice!\n        return nil\n    }),\n    NewFuncStep(\"branch2\", func(ctx context.Context, s *State) error {\n        items := s.Get(\"items\").([]string)\n        // items[0] is now \"modified\" - unexpected!\n        return nil\n    }),\n)\n```\n\n## Solution\n\n### 1. Add `DeepClone()` to Store\n\nUse JSON round-trip for deep copying. This is simple and consistent with Store's existing JSON-based persistence.\n\n```go\n// DeepClone creates a deep copy of the store using JSON serialization.\n// All values must be JSON-serializable. Type information for custom structs\n// is not preserved - they become map[string]any after cloning.\nfunc (s *Store) DeepClone() (*Store, error) {\n    s.mu.RLock()\n    defer s.mu.RUnlock()\n    \n    clone := New(nil)\n    for k, v := range s.cache {\n        data, err := json.Marshal(v)\n        if err != nil {\n            return nil, \u0026SerializationError{Key: k, Err: err}\n        }\n        var cloned any\n        if err := json.Unmarshal(data, \u0026cloned); err != nil {\n            return nil, \u0026SerializationError{Key: k, Err: err}\n        }\n        clone.cache[k] = cloned\n    }\n    return clone, nil\n}\n```\n\n### 2. Update Parallel to use DeepClone\n\n```go\n// In Run() - line ~69\nbranchState, err := state.DeepClone()\nif err != nil {\n    return nil, fmt.Errorf(\"failed to clone state for branch %q: %w\", step.Name(), err)\n}\n\n// In RunStream() - line ~171\nbranchState, err := state.DeepClone()\nif err != nil {\n    event.Emit(ch, Event{Type: event.RunError, Error: ...})\n    return\n}\n```\n\n## Trade-offs\n\n### JSON Round-Trip Approach\n\n**Pros:**\n- Simple implementation\n- No external dependencies\n- Consistent with Store's persistence model\n- Handles nested structures correctly\n\n**Cons:**\n- Type information lost for custom structs (`*MyStruct` → `map[string]any`)\n- Non-JSON-serializable values cause errors\n- Slightly slower than shallow clone\n\n### Alternative: Reflection-Based Deep Copy\n\nCould use reflection or a library like `mohae/deepcopy` to preserve types. More complex but type-preserving.\n\n**Decision:** Start with JSON approach. It covers 90% of use cases. Document the type limitation. If users need type preservation, they can:\n1. Re-assert types after branch completion\n2. Use primitives/maps in shared state\n3. Store typed values only in outputKey (which aggregator handles)\n\n## Type Limitation Mitigation\n\nThe type loss primarily affects reading from branch states. The aggregator pattern already handles this:\n\n```go\n// Aggregator receives branch states and merges into parent\n// Users typically read specific keys they know the types of\nNewParallel(\"p\", steps...).WithAggregator(func(parent *State, results []*StepResult) {\n    for _, r := range results {\n        branch := GetBranchState(r)\n        // Read known keys with expected types\n        count := branch.GetInt(\"count\")  // Works - primitives preserved\n        parent.Set(\"total\", parent.GetInt(\"total\") + count)\n    }\n})\n```\n\nFor structured data, recommend storing under typed keys before branching:\n```go\n// Before parallel: state has *Analysis under \"analysis\"\n// After parallel: branches have map[string]any under \"analysis\"\n// Solution: Use aggregator to re-type if needed, or store primitives\n```\n\n## Changes Required\n\n### internal/store/store.go\n1. Add `DeepClone() (*Store, error)` method\n\n### workflow/parallel.go\n1. Update `Run()` to use `DeepClone()` instead of `Clone()` (line ~69)\n2. Update `RunStream()` to use `DeepClone()` instead of `Clone()` (line ~171)\n3. Add error handling for clone failures\n\n### Documentation\n1. Document `DeepClone()` behavior and type limitations\n2. Update Parallel godoc to mention deep cloning\n3. Add example showing safe branch state usage\n\n## Files\n\n- `internal/store/store.go`\n- `workflow/parallel.go`","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-19T08:36:46.548937736-08:00","updated_at":"2025-12-19T08:36:59.169557132-08:00","dependencies":[{"issue_id":"gains-vos","depends_on_id":"gains-0a9","type":"blocks","created_at":"2025-12-19T09:23:34.401022723-08:00","created_by":"daemon"}]}
{"id":"gains-xyy","title":"Consolidate ToolStep and TypedToolStep into ToolStep[T]","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-18T20:40:25.573069112-08:00","updated_at":"2025-12-18T20:48:34.970933783-08:00","closed_at":"2025-12-18T20:48:34.970933783-08:00","close_reason":"Closed"}
